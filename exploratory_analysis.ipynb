{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michelin Star Restaurant Guide Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Attributes\n",
    "\n",
    "- **Name**: The name of the Michelin-starred restaurant.\n",
    "- **Address**: The full street address of the restaurant.\n",
    "- **Location**: The city and country where the restaurant is located.\n",
    "- **Price**: Price range indicator, using $ symbols (e.g. $$$$ for very expensive).\n",
    "- **Cuisine**: The type or style of cuisine served at the restaurant.\n",
    "- **Longitude**: The geographic longitude coordinate of the restaurant's location.\n",
    "- **Latitude**: The geographic latitude coordinate of the restaurant's location.\n",
    "- **PhoneNumber**: The contact phone number for the restaurant.\n",
    "- **Url**: The URL of the restaurant's page on the official Michelin Guide website.\n",
    "- **WebsiteUrl**: The URL of the restaurant's own official website.\n",
    "- **Award**: The Michelin star rating awarded to the restaurant (e.g. \"3 Stars\").\n",
    "- **GreenStar**: A binary indicator (0 or 1) of whether the restaurant has received a Michelin Green Star for sustainability.\n",
    "- **FacilitiesAndServices**: A list of amenities and services offered by the restaurant.\n",
    "- **Description**: A brief description of the restaurant, often including details about the chef and cuisine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r .\\requirements.txt\n",
    "# %pip install -q pandas plotly dash dash-bootstrap-components pyarrow python-dotenv\n",
    "# %pip freeze > requirements.txt # WARNING!! run this only on a linux distro or wsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pandas import DataFrame\n",
    "from pandas._typing import ArrayLike\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/michelin_by_Jerry_Ng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def clean_data(df: DataFrame):\n",
    "    # Split text using string ',' in column: 'Location'\n",
    "    loc_0 = df.columns.get_loc(\"Location\")\n",
    "    df_clean_split = (\n",
    "        df[\"Location\"].str.split(pat=\",\", expand=True).add_prefix(\"Location_\")\n",
    "    )\n",
    "    df = pd.concat([df.iloc[:, :loc_0], df_clean_split, df.iloc[:, loc_0:]], axis=1)\n",
    "    # Rename column 'Location_0' to 'Location_city'\n",
    "    df = df.rename(columns={\"Location_0\": \"Location_city\"})\n",
    "    # Rename column 'Location_1' to 'Location_country'\n",
    "    df = df.rename(columns={\"Location_1\": \"Location_country\"})\n",
    "    # Fill missing country values with this dict\n",
    "    city_country_map = {\n",
    "        \"Singapore\": \"Singapore\",\n",
    "        \"Hong Kong\": \"China\",\n",
    "        \"Macau\": \"China\",\n",
    "        \"Dubai\": \"United Arab Emirates\",\n",
    "        \"Luxembourg\": \"Luxembourg\",\n",
    "        \"Abu Dhabi\": \"United Arab Emirates\",\n",
    "    }\n",
    "    df[\"Location_country\"] = df[\"Location_country\"].fillna(\n",
    "        df[\"Location_city\"].map(city_country_map)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df_clean = clean_data(df.copy())\n",
    "df_clean.head()\n",
    "\n",
    "\n",
    "def select_unique_location_city_where_location_country_is_missing(\n",
    "    df_clean_1: DataFrame,\n",
    ") -> ArrayLike:\n",
    "    # Filter rows based on column: 'Location_country'\n",
    "    df_clean_1 = df_clean_1[df_clean_1[\"Location_country\"].isna()]\n",
    "    return df_clean_1[\"Location_city\"].unique()\n",
    "\n",
    "\n",
    "missing_countries = select_unique_location_city_where_location_country_is_missing(\n",
    "    df_clean.copy()\n",
    ")\n",
    "if missing_countries.size > 0:\n",
    "    missing_countries\n",
    "    raise Exception(\"Missing countries found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def standardize_price(price):\n",
    "    if pd.isna(price):\n",
    "        return \"Unknown\"\n",
    "\n",
    "    return \"$\" * len(price)\n",
    "\n",
    "\n",
    "def clean_data(df: DataFrame):\n",
    "    # Created column 'Standardized_Price' from formula\n",
    "    df[\"Standardized_Price\"] = df[\"Price\"].apply(standardize_price)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_clean_1 = clean_data(df_clean.copy())\n",
    "df_clean_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FacilitiesAndServices columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with Name, Address, and all facilities and services in one column\n",
    "df_facilitiesandservices = df[[\"Name\", \"Address\", \"FacilitiesAndServices\"]].copy()\n",
    "df_facilitiesandservices[\"FacilitiesAndServices\"] = df_facilitiesandservices[\n",
    "    \"FacilitiesAndServices\"\n",
    "].str.split(\",\")\n",
    "df_facilitiesandservices = df_facilitiesandservices.explode(\"FacilitiesAndServices\")\n",
    "df_facilitiesandservices[\"FacilitiesAndServices\"] = df_facilitiesandservices[\n",
    "    \"FacilitiesAndServices\"\n",
    "].str.strip()\n",
    "\n",
    "# df_facilitiesandservices = df_facilitiesandservices.reset_index(drop=True)\n",
    "\n",
    "df_facilitiesandservices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with Name, Address, and all cuisines in one column\n",
    "df_cuisine = df[[\"Name\", \"Address\", \"Cuisine\"]].copy()\n",
    "df_cuisine[\"Cuisine\"] = df_cuisine[\"Cuisine\"].str.split(\",\")\n",
    "df_cuisine = df_cuisine.explode(\"Cuisine\")\n",
    "df_cuisine[\"Cuisine\"] = df_cuisine[\"Cuisine\"].str.strip()\n",
    "\n",
    "# Reset the index\n",
    "# df_cuisine = df_cuisine.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "df_cuisine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_col = df_clean_1[[\"Name\", \"Address\"]].value_counts()\n",
    "\n",
    "if primary_col[primary_col > 1].size > 0:\n",
    "    primary_col[primary_col > 1]\n",
    "    raise Exception(\"Duplicate records found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df_clean_1.isna().sum()\n",
    "_[_ > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        df_clean_1.describe(include=[\"object\"]).loc[\n",
    "            :,\n",
    "            [\n",
    "                \"Location_city\",\n",
    "                \"Location_country\",\n",
    "                \"Standardized_Price\",\n",
    "                \"Award\",\n",
    "            ],\n",
    "        ],\n",
    "        df[\"GreenStar\"].astype(\"object\").describe(),\n",
    "        df_cuisine.describe()[\"Cuisine\"],\n",
    "        df_facilitiesandservices.describe()[\"FacilitiesAndServices\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
